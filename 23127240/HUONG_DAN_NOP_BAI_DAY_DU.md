# HÆ¯á»šNG DáºªN Ná»˜P BÃ€I Äáº¦Y Äá»¦ - LAB 1

## ğŸ“‹ TÃ“M Táº®T YÃŠU Cáº¦U

Theo giáº£ng viÃªn, báº¡n cáº§n ná»™p 3 pháº§n riÃªng biá»‡t:

1. **MÃ£ nguá»“n (Source Code)** â†’ Ná»™p lÃªn **MOODLE**
2. **Cháº¡y & Benchmark** â†’ Cháº¡y trÃªn **GOOGLE COLAB (CPU-only)**
3. **Dá»¯ liá»‡u (Results)** â†’ Ná»™p lÃªn **GOOGLE DRIVE**

---

## ğŸ¯ PHáº¦N 1: CHUáº¨N Bá»Š MÃƒ NGUá»’N (CHO MOODLE)

### BÆ°á»›c 1: Táº¡o thÆ° má»¥c ná»™p bÃ i

```
23127240/
â”œâ”€â”€ src/                        # MÃ£ nguá»“n
â”‚   â”œâ”€â”€ main.py
â”‚   â”œâ”€â”€ arxiv_scraper.py
â”‚   â”œâ”€â”€ reference_scraper.py
â”‚   â”œâ”€â”€ config.py
â”‚   â”œâ”€â”€ utils.py
â”‚   â””â”€â”€ requirements.txt       # â­ Báº®T BUá»˜C
â”œâ”€â”€ README.md                   # â­ Báº®T BUá»˜C - HÆ°á»›ng dáº«n cháº¡y
â””â”€â”€ Report.docx                 # â­ Báº®T BUá»˜C - BÃ¡o cÃ¡o + link video
```

### BÆ°á»›c 2: Táº¡o requirements.txt

```bash
cd /Users/nhutphan/Desktop/testLai/23127240/src
```

Táº¡o file `requirements.txt`:
```txt
arxiv
requests
beautifulsoup4
bibtexparser
psutil
```

### BÆ°á»›c 3: Viáº¿t README.md chi tiáº¿t

File `README.md` pháº£i bao gá»“m:
- Python version (vÃ­ dá»¥: Python 3.8+)
- CÃ¡ch cÃ i Ä‘áº·t dependencies
- **CÃ¡ch cháº¡y trÃªn Google Colab** (quan trá»ng!)
- Cáº¥u hÃ¬nh paper range
- Giáº£i thÃ­ch vá» performance metrics

### BÆ°á»›c 4: NÃ©n vÃ  ná»™p lÃªn Moodle

```bash
cd /Users/nhutphan/Desktop/testLai
zip -r 23127240.zip 23127240/ -x "*/23127240_data/*" -x "*/__pycache__/*" -x "*/.DS_Store"
```

**Upload `23127240.zip` lÃªn Moodle**

---

## ğŸš€ PHáº¦N 2: CHáº Y TRÃŠN GOOGLE COLAB (CPU-ONLY)

### BÆ°á»›c 1: ÄÆ°a code lÃªn GitHub (Ä‘á»ƒ dá»… clone vÃ o Colab)

```bash
# Trong thÆ° má»¥c dá»± Ã¡n
cd /Users/nhutphan/Desktop/testLai/23127240

# Khá»Ÿi táº¡o git (náº¿u chÆ°a cÃ³)
git init
git add .
git commit -m "Initial commit for Lab 1"

# Push lÃªn GitHub
git remote add origin https://github.com/nhutphansayhi/ScrapingData.git
git push -u origin master
```

### BÆ°á»›c 2: Má»Ÿ Google Colab

1. Truy cáº­p: https://colab.research.google.com/
2. **File > New notebook**
3. Äáº·t tÃªn: `ArXiv_Scraper_23127240_Final.ipynb`
4. **Runtime > Change runtime type > Hardware accelerator > None** (CPU-only)

### BÆ°á»›c 3: Cháº¡y cÃ¡c cell theo thá»© tá»±

#### Cell 1: Kiá»ƒm tra Runtime
```python
import psutil
import platform

print("=" * 60)
print("RUNTIME INFO - Lab 1 Testbed")
print("=" * 60)
print(f"OS: {platform.system()} {platform.release()}")
print(f"CPU cores: {psutil.cpu_count()}")
print(f"RAM: {psutil.virtual_memory().total / (1024**3):.2f} GB")
print(f"Disk: {psutil.disk_usage('/').total / (1024**3):.2f} GB")
print("=" * 60)

# Verify CPU-only
try:
    import torch
    if torch.cuda.is_available():
        print("\nâš ï¸  WARNING: GPU detected! Switch to CPU-only")
    else:
        print("\nâœ… CPU-only mode - Correct!")
except:
    print("\nâœ… CPU-only mode - Correct!")
```

#### Cell 2: Clone tá»« GitHub
```python
!git clone https://github.com/nhutphansayhi/ScrapingData.git
%cd ScrapingData/23127240
!ls -la src/
```

#### Cell 3: Install dependencies
```python
!pip install -q -r src/requirements.txt

import arxiv
import requests
from bs4 import BeautifulSoup
import bibtexparser
import psutil
import json
import time
from datetime import datetime

print("âœ… All dependencies installed!")
```

#### Cell 4: Setup Performance Monitor
```python
import psutil
import time
import os
from datetime import datetime

class PerformanceMonitor:
    def __init__(self):
        self.start_time = None
        self.end_time = None
        self.max_ram_mb = 0
        self.initial_disk_mb = 0
        
    def start(self):
        self.start_time = time.time()
        self.initial_disk_mb = psutil.disk_usage('/').used / (1024**2)
        print(f"ğŸš€ Started at: {datetime.now()}")
        print(f"Initial RAM: {psutil.virtual_memory().used / (1024**2):.2f} MB")
        
    def update_metrics(self):
        current_ram_mb = psutil.virtual_memory().used / (1024**2)
        self.max_ram_mb = max(self.max_ram_mb, current_ram_mb)
        
    def finish(self, output_dir="23127240_data"):
        self.end_time = time.time()
        total_time = self.end_time - self.start_time
        
        final_disk_mb = psutil.disk_usage('/').used / (1024**2)
        disk_increase = final_disk_mb - self.initial_disk_mb
        
        output_size = 0
        if os.path.exists(output_dir):
            output_size = sum(
                os.path.getsize(os.path.join(dp, f))
                for dp, dn, filenames in os.walk(output_dir)
                for f in filenames
            ) / (1024**2)
        
        print("\n" + "=" * 70)
        print("ğŸ“Š PERFORMANCE METRICS - LAB 1")
        print("=" * 70)
        print(f"\nâ±ï¸  WALL TIME: {total_time:.2f}s ({total_time/60:.2f} min)")
        print(f"ğŸ’¾ MAX RAM: {self.max_ram_mb:.2f} MB ({self.max_ram_mb/1024:.2f} GB)")
        print(f"ğŸ’¿ DISK INCREASE: {disk_increase:.2f} MB")
        print(f"ğŸ“¦ OUTPUT SIZE: {output_size:.2f} MB")
        print("=" * 70)
        
        return {
            'testbed': 'Google Colab CPU-only',
            'wall_time_seconds': total_time,
            'wall_time_minutes': total_time / 60,
            'max_ram_mb': self.max_ram_mb,
            'disk_increase_mb': disk_increase,
            'output_size_mb': output_size,
            'timestamp': datetime.now().isoformat()
        }

monitor = PerformanceMonitor()
print("âœ… Monitor ready!")
```

#### Cell 5: Cháº¡y Scraper (END-TO-END)
```python
# START MONITORING
monitor.start()

# Di chuyá»ƒn vÃ o src
%cd /content/ScrapingData/23127240/src

# Kiá»ƒm tra file cÃ³ sáºµn
print("ğŸ“‚ Available Python files:")
!ls -la *.py

# Cháº¡y scraper (thay main.py báº±ng tÃªn file Ä‘Ãºng náº¿u cáº§n)
print("\nğŸš€ Running scraper...")
!python3 main.py

# Cáº­p nháº­t metrics
monitor.update_metrics()

# Vá» thÆ° má»¥c gá»‘c
%cd /content/ScrapingData/23127240

# FINISH MONITORING
metrics = monitor.finish()

# LÆ°u metrics
with open('performance_metrics.json', 'w') as f:
    json.dump(metrics, f, indent=2)

print("\nâœ… Scraping completed!")
print("ğŸ’¾ Metrics saved to performance_metrics.json")
```

#### Cell 6: Verify Data Structure
```python
import os
import json

data_dir = "23127240_data"

if os.path.exists(data_dir):
    papers = [d for d in os.listdir(data_dir) 
              if os.path.isdir(os.path.join(data_dir, d))]
    
    print(f"ğŸ“Š Total papers: {len(papers)}")
    
    # Check first paper
    if papers:
        paper = papers[0]
        paper_path = os.path.join(data_dir, paper)
        
        print(f"\nğŸ“„ Sample paper: {paper}")
        print(f"  - tex/ exists: {os.path.exists(os.path.join(paper_path, 'tex'))}")
        print(f"  - metadata.json exists: {os.path.exists(os.path.join(paper_path, 'metadata.json'))}")
        print(f"  - references.json exists: {os.path.exists(os.path.join(paper_path, 'references.json'))}")
else:
    print("âŒ Data directory not found!")
```

---

## ğŸ’¾ PHáº¦N 3: Ná»˜P Dá»® LIá»†U LÃŠN GOOGLE DRIVE

### BÆ°á»›c 1: NÃ©n dá»¯ liá»‡u trong Colab

#### Cell 7: Zip data
```python
import shutil

# NÃ©n dá»¯ liá»‡u
print("ğŸ“¦ Compressing data...")
shutil.make_archive('23127240_data', 'zip', '.', '23127240_data')

size_mb = os.path.getsize('23127240_data.zip') / (1024**2)
print(f"âœ… Created: 23127240_data.zip")
print(f"ğŸ“Š Size: {size_mb:.2f} MB ({size_mb/1024:.2f} GB)")
```

### BÆ°á»›c 2: Upload lÃªn Google Drive

#### Cell 8: Mount Drive vÃ  Copy
```python
from google.colab import drive

# Mount Google Drive
drive.mount('/content/drive')

# Copy file lÃªn Drive
!cp 23127240_data.zip /content/drive/MyDrive/
!cp performance_metrics.json /content/drive/MyDrive/

print("âœ… Files uploaded to Google Drive:")
print("   - 23127240_data.zip")
print("   - performance_metrics.json")
```

### BÆ°á»›c 3: Upload vÃ o thÆ° má»¥c giáº£ng viÃªn chá»‰ Ä‘á»‹nh

1. Má»Ÿ Google Drive trÃªn trÃ¬nh duyá»‡t
2. TÃ¬m file `23127240_data.zip` trong **My Drive**
3. **Di chuyá»ƒn hoáº·c copy** file nÃ y vÃ o **thÆ° má»¥c Google Drive do giáº£ng viÃªn cung cáº¥p**
4. Äáº£m báº£o file cÃ³ tÃªn Ä‘Ãºng: `23127240.zip` (theo Student ID)

---

## ğŸ“ PHáº¦N 4: HOÃ€N THIá»†N BÃO CÃO

### Trong Report.docx, báº¡n cáº§n ghi:

#### 1. Testbed
```
Testbed: Google Colab instance, CPU-only mode
OS: Linux (tá»« Cell 1)
CPU: X cores (tá»« Cell 1)
RAM: Y GB (tá»« Cell 1)
```

#### 2. Running Time (Wall Time)
```
Total wall time: X seconds (Y minutes)
Average per paper: Z seconds
Papers processed: N papers
```

#### 3. Memory Footprint
```
Maximum RAM used: X MB (Y GB)
Disk increase: Z MB
Output data size: W MB
```

#### 4. Data Statistics
```
Total papers scraped: N
Papers with TeX sources: X
Papers with metadata: Y
Papers with references: Z
Success rate: XX%
```

#### 5. Link YouTube Video
```
Video demo: https://youtube.com/watch?v=xxxxx
(Video â‰¤120 giÃ¢y, cÃ´ng khai, giá»¯ Ã­t nháº¥t 1 thÃ¡ng sau khi cÃ³ Ä‘iá»ƒm)
```

---

## ğŸ¬ PHáº¦N 5: QUAY VIDEO DEMO (â‰¤120 GIÃ‚Y)

### Script video (120s):

**[0-15s] Setup**
- "Xin chÃ o, tÃ´i lÃ  sinh viÃªn MSSV 23127240"
- "ÄÃ¢y lÃ  demo Lab 1 cháº¡y trÃªn Google Colab CPU-only"
- Show Runtime settings (CPU-only)

**[15-30s] Clone & Setup**
- Clone repository tá»« GitHub
- Install dependencies
- Show code structure

**[30-75s] Running**
- Cháº¡y scraper
- Show logs: downloading, extracting, removing figures
- Show performance metrics trong quÃ¡ trÃ¬nh cháº¡y

**[75-105s] Results**
- Show performance metrics cuá»‘i cÃ¹ng
- Verify data structure
- Show má»™t paper máº«u (tex/, metadata.json, references.json)

**[105-120s] Summary**
- TÃ³m táº¯t: "Scraper Ä‘Ã£ cháº¡y thÃ nh cÃ´ng trÃªn Colab CPU-only"
- "Äo Ä‘Æ°á»£c wall time X phÃºt, max RAM Y GB"
- "Dá»¯ liá»‡u Ä‘Ã£ Ä‘Æ°á»£c ná»™p lÃªn Google Drive"

---

## âœ… CHECKLIST TRÆ¯á»šC KHI Ná»˜P

### Moodle (Source Code):
- [ ] File 23127240.zip chá»©a src/, README.md, Report.docx
- [ ] requirements.txt Ä‘áº§y Ä‘á»§
- [ ] README.md cÃ³ hÆ°á»›ng dáº«n cháº¡y trÃªn Colab
- [ ] Report.docx cÃ³ link video YouTube

### Google Drive (Data):
- [ ] File 23127240_data.zip (hoáº·c 23127240.zip)
- [ ] Upload vÃ o Ä‘Ãºng thÆ° má»¥c giáº£ng viÃªn chá»‰ Ä‘á»‹nh
- [ ] File khÃ´ng corrupt, cÃ³ thá»ƒ extract Ä‘Æ°á»£c

### YouTube (Video):
- [ ] Video â‰¤120 giÃ¢y
- [ ] CÃ´ng khai (Public)
- [ ] Link Ä‘Ã£ copy vÃ o Report.docx
- [ ] ÄÃ£ test link hoáº¡t Ä‘á»™ng

### Colab (Benchmark):
- [ ] ÄÃ£ cháº¡y trÃªn CPU-only mode
- [ ] CÃ³ performance metrics
- [ ] Káº¿t quáº£ Ä‘Ã£ verify

---

## ğŸ¯ LUá»’NG CÃ”NG VIá»†C Tá»”NG THá»‚

```
1. Viáº¿t code local
   â†“
2. Test local
   â†“
3. Push code lÃªn GitHub
   â†“
4. NÃ©n code â†’ Ná»™p MOODLE (23127240.zip)
   â†“
5. Má»Ÿ Google Colab (CPU-only)
   â†“
6. Clone tá»« GitHub vÃ o Colab
   â†“
7. Cháº¡y scraper + Ä‘o metrics
   â†“
8. NÃ©n dá»¯ liá»‡u â†’ Upload Google Drive
   â†“
9. Copy file vÃ o thÆ° má»¥c giáº£ng viÃªn
   â†“
10. Ghi metrics vÃ o Report.docx
   â†“
11. Quay video demo
   â†“
12. Upload YouTube + copy link vÃ o Report
   â†“
13. Update Report.docx trong file ná»™p Moodle
   â†“
14. HOÃ€N Táº¤T! âœ…
```

---

## ğŸ“ LÆ¯U Ã QUAN TRá»ŒNG

1. **Code trÃªn GitHub**: Chá»‰ Ä‘á»ƒ tiá»‡n clone vÃ o Colab, KHÃ”NG pháº£i nÆ¡i ná»™p chÃ­nh thá»©c
2. **Testbed báº¯t buá»™c**: Google Colab CPU-only (khÃ´ng Ä‘Æ°á»£c dÃ¹ng GPU hay mÃ¡y local)
3. **3 nÆ¡i ná»™p khÃ¡c nhau**:
   - Moodle: Source code + Report + README
   - Google Drive: Dá»¯ liá»‡u Ä‘Ã£ scrape
   - YouTube: Video demo
4. **KhÃ´ng Ä‘Æ°á»£c ná»™p muá»™n**: Äáº£m báº£o ná»™p Ä‘Ãºng deadline

---

**ChÃºc báº¡n hoÃ n thÃ nh xuáº¥t sáº¯c Lab 1! ğŸš€**
